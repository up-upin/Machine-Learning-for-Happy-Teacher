{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3930a974-8ebd-4365-a3bc-21b3a314428e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "#from sklearn.inspection import plot_partial_dependence\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import make_gaussian_quantiles\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from collections import Counter\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "from sklearn.inspection import permutation_importance\n",
    "import pickle\n",
    "import shap\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.cm as cm\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def calc_metrics(y_test, preds):\n",
    "    accuracy = accuracy_score(y_test, preds)\n",
    "    precision = precision_score(y_test, preds)\n",
    "    recall = recall_score(y_test, preds)\n",
    "    f1score = f1_score(y_test, preds)\n",
    "    return (accuracy, precision, recall, f1score)\n",
    "\n",
    "def model_predict(model, x_train, y_train, x_test, y_test):\n",
    "    model = model.fit(x_train, y_train)\n",
    "    y_predict_train = model.predict(x_train)\n",
    "    y_predict_test = model.predict(x_test)\n",
    "    return accuracy_score(y_predict_train, y_train), accuracy_score(y_predict_test, y_test), y_predict_test\n",
    "\n",
    "def sort_feature(feature_names, feature_vals):\n",
    "    assert len(feature_names) == len(feature_vals)\n",
    "    x_and_y = [(x, y) for x, y in zip(feature_names, feature_vals)]\n",
    "    x_and_y.sort(key = lambda x: -x[1])\n",
    "    return [item[0] for item in x_and_y], [item[1] for item in x_and_y]\n",
    "\n",
    "def get_feature_importance(model, x_test, y_test):\n",
    "    perm_importance = permutation_importance(model, x_test, y_test)\n",
    "    perm_sorted_idx = perm_importance.importances_mean.argsort()\n",
    "    explainer = shap.TreeExplainer(model)\n",
    "    shap_values = explainer.shap_values(x_test)\n",
    "    return (model.feature_importances_, perm_sorted_idx, shap_values)\n",
    "\n",
    "def machine_learning(x, y, split_ratio=0.3, random_seed=28):\n",
    "    xstd = x.std()\n",
    "    xmean = x.mean()\n",
    "\n",
    "    x = (x - x.mean()) / x.std()\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=split_ratio, random_state=random_seed,\n",
    "                                                        shuffle=True)\n",
    "    xtestvalue = x_test * xstd + xmean\n",
    "\n",
    "    map = {}\n",
    "\n",
    "    # LightGBM\n",
    "    print(\"Starting LightGBM。。。\")\n",
    "    time1 = time.time()\n",
    "    gbm = lgb.LGBMClassifier(random_state=random_seed)\n",
    "    score_train, score_test, y_predict_test = model_predict(gbm, x_train, y_train, x_test, y_test)\n",
    "    y_pred_proba = gbm.predict_proba(x_test)[:, 1]\n",
    "\n",
    "    dt_featureimprotance, permsortedidx, shapevalues = get_feature_importance(gbm, x_test, y_test)\n",
    "\n",
    "    map['LightGBM'] = (\n",
    "    dt_featureimprotance, permsortedidx, xstd, xmean, xtestvalue, shapevalues, x_test, y_test, y_pred_proba)\n",
    "\n",
    "    calc_metrics(y_test, y_predict_test)\n",
    "\n",
    "    return map\n",
    "\n",
    "def K_Means(df, cluster_raw, k):\n",
    "    # 提取特征列\n",
    "    X = df[cluster_raw].values\n",
    "\n",
    "    # 初始化KMeans对象并进行拟合\n",
    "    kmeans = KMeans(n_clusters=k, random_state=0)\n",
    "    kmeans.fit(X)\n",
    "\n",
    "    # 获取聚类中心和标签\n",
    "    centroids = kmeans.cluster_centers_\n",
    "    labels = kmeans.labels_\n",
    "\n",
    "    # 将聚类标签添加为DataFrame的一个新列\n",
    "    df['cluster_label'] = labels\n",
    "\n",
    "    # 返回带有聚类标签的DataFrame、聚类中心和标签\n",
    "    return df, centroids, labels\n",
    "\n",
    "result_map = {}\n",
    "\n",
    "csv_file_path = r\"C:\\Users\\29688\\Desktop\\study-2\\sj_T1\\T1.xlsx\"\n",
    "df = pd.read_excel(csv_file_path)\n",
    "# 设置特征列，并且根据这些特征进行聚类\n",
    "cluster_raw = ['LS', 'ladder', 'PMWB']\n",
    "k = 3\n",
    "\n",
    "# 调用K_Means函数\n",
    "df, centroids, labels = K_Means(df, cluster_raw, k)\n",
    "\n",
    "# 打印每个编号对应的聚类标签\n",
    "print(\"查看每个编号对应的聚类标签：\")\n",
    "print(df[['ID', 'cluster_label']])  # 假设'Number'列存在于df中\n",
    "\n",
    "# 打印聚类标签和聚类中心\n",
    "print(\"聚类标签:\", labels)\n",
    "print(\"聚类中心:\", centroids)\n",
    "\n",
    "# 根据聚类标签创建二进制变量列\n",
    "df['high_binary'] = (df['cluster_label'] == 2).astype(int)  # 2表示高类别\n",
    "df['middle_binary'] = (df['cluster_label'] == 0).astype(int)  # 1表示中类别\n",
    "df['low_binary'] = (df['cluster_label'] == 1).astype(int)  # 0表示低类别\n",
    "\n",
    "# 保存修改后的 DataFrame 到 CSV 文件\n",
    "df.to_excel(csv_file_path)\n",
    "\n",
    "# 打印修改后的 DataFrame 头部，以确认结果\n",
    "print(df.head())\n",
    "\n",
    "df = pd.read_excel (r\"C:\\Users\\29688\\Desktop\\预处理_T1匹配_1.xlsx\")\n",
    "columns_to_replace = ['PRO', 'gender', 'age', 'height', 'weight','marriage', 'kid', 'Kage',\n",
    "             'BKage', 'LKage', 'education','shifan', 'xueduan', 'BZR',\n",
    "             'subject', 'title', 'Tage', 'DEP', 'ANX', 'LON', 'RES', 'STR', 'sleep',\n",
    "             'rise', 'commute', 'work', 'mediation', 'sport', 'location_type', 'school_type']\n",
    "\n",
    "# 遍历需要替换的列\n",
    "for column in columns_to_replace:\n",
    "    # 尝试将列中的字符串转换为数值，并将空字符串替换为NaN\n",
    "    df[column] = pd.to_numeric(df[column].replace('', np.nan), errors='coerce')\n",
    "\n",
    "    # 计算该列的中位数\n",
    "    median = df[column].median()\n",
    "\n",
    "    # 使用中位数替换NaN值\n",
    "    # 这里不需要使用inplace=True，因为我们已经直接赋值给df[column]\n",
    "    df[column] = df[column].fillna(median)\n",
    "\n",
    "# 将修改后的DataFrame保存回CSV文件\n",
    "df.to_excel(r\"C:\\Users\\29688\\Desktop\\预处理_T1匹配_1.xlsx\")\n",
    "\n",
    "df = pd.read_excel (r\"C:\\Users\\29688\\Desktop\\预处理_T1匹配_1.xlsx\")\n",
    "# 自变量\n",
    "df_src = df[['PRO', 'gender', 'age', 'height', 'weight','marriage', 'kid', 'Kage',\n",
    "             'BKage', 'LKage', 'education','shifan', 'xueduan', 'BZR',\n",
    "             'subject', 'title', 'Tage', 'DEP', 'ANX', 'LON', 'RES', 'STR', 'sleep',\n",
    "             'rise', 'commute', 'work', 'mediation', 'sport', 'location_type', 'school_type']].astype(float)\n",
    "# 因变量\n",
    "df_tgt = df[['high_binary']]\n",
    "print(\"Data prepare done\")\n",
    "\n",
    "for i in range(1):\n",
    "    result_map[i] = machine_learning(df_src, df_tgt.values.ravel(), random_seed=i)\n",
    "\n",
    "    for model_name, vals in result_map[0].items():\n",
    "        shap.summary_plot(vals[-4], vals[-5])\n",
    "        save_path_1 = 'high_shap_value_plot.png'\n",
    "    # 保存图片\n",
    "        plt.savefig(save_path_1, bbox_inches='tight')\n",
    "    import seaborn as sns\n",
    "\n",
    "    sns.set_theme(style=\"darkgrid\")\n",
    "\n",
    "\n",
    "def cross_validation(model, _X, _y, _cv=10):\n",
    "    '''Function to perform 5 Folds Cross-Validation\n",
    "     Parameters\n",
    "     ----------\n",
    "    model: Python Class, default=None\n",
    "            This is the machine learning algorithm to be used for training.\n",
    "    _X: array\n",
    "         This is the matrix of features.\n",
    "    _y: array\n",
    "         This is the target variable.\n",
    "    _cv: int, default=10\n",
    "        Determines the number of folds for cross-validation.\n",
    "     Returns\n",
    "     -------\n",
    "     The function returns a dictionary containing the metrics 'accuracy', 'precision',\n",
    "     'recall', 'f1' for both training set and validation set.\n",
    "    '''\n",
    "    _scoring = ['accuracy', 'precision', 'recall', 'f1']\n",
    "    results = cross_validate(estimator=model,\n",
    "                             X=_X,\n",
    "                             y=_y,\n",
    "                             cv=_cv,\n",
    "                             scoring=_scoring,\n",
    "                             return_train_score=True)\n",
    "    return {\"Training Accuracy scores\": results['train_accuracy'],\n",
    "            \"Mean Training Accuracy\": results['train_accuracy'].mean() * 100,\n",
    "            \"Validation Accuracy scores\": results['test_accuracy'],\n",
    "            \"Mean Validation Accuracy\": results['test_accuracy'].mean() * 100\n",
    "            }\n",
    "\n",
    "def plot_result(x_label, y_label, plot_title, train_data, val_data):\n",
    "    '''Function to plot a grouped bar chart showing the training and validation\n",
    "      results of the ML model in each fold after applying K-fold cross-validation.\n",
    "     Parameters\n",
    "     ----------\n",
    "     x_label: str,\n",
    "        Name of the algorithm used for training e.g 'Decision Tree'\n",
    "\n",
    "     y_label: str,\n",
    "        Name of metric being visualized e.g 'Accuracy'\n",
    "     plot_title: str,\n",
    "        This is the title of the plot e.g 'Accuracy Plot'\n",
    "\n",
    "     train_result: list, array\n",
    "        This is the list containing either training precision, accuracy, or f1 score.\n",
    "\n",
    "     val_result: list, array\n",
    "        This is the list containing either validation precision, accuracy, or f1 score.\n",
    "     Returns\n",
    "     -------\n",
    "     The function returns a Grouped Barchart showing the training and validation result\n",
    "     in each fold.\n",
    "    '''\n",
    "\n",
    "    # Set size of plot\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    labels = [\"1st Fold\", \"2nd Fold\", \"3rd Fold\", \"4th Fold\", \"5th Fold\", \"6st Fold\", \"7nd Fold\", \"8rd Fold\",\n",
    "              \"9th Fold\", \"10th Fold\"]\n",
    "    X_axis = np.arange(len(labels))\n",
    "    ax = plt.gca()\n",
    "    plt.ylim(0.40000, 1)\n",
    "    plt.bar(X_axis - 0.2, train_data, 0.4, color='blue', label='Training')\n",
    "    plt.bar(X_axis + 0.2, val_data, 0.4, color='red', label='Validation')\n",
    "    plt.title(plot_title, fontsize=24)\n",
    "    plt.xticks(X_axis, labels)\n",
    "    plt.xlabel(x_label, fontsize=18)\n",
    "    plt.ylabel(y_label, fontsize=18)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    save_path_2 = 'high_grouped_barplot_accuracy.png'\n",
    "    plt.savefig(save_path_2)\n",
    "    plt.show()\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(df_src, df_tgt.values.ravel(), test_size = 0.3, random_state = 28, shuffle = True)\n",
    "\n",
    "gbm = lgb.LGBMClassifier(random_state=28)\n",
    "gbm_result = cross_validation(gbm, x_test, y_test, 10)\n",
    "print(gbm_result)\n",
    "\n",
    "model_name = \"lightgbm\"\n",
    "plot_result(model_name,\n",
    "            \"Accuracy\",\n",
    "            \"High Well Being string Victimization: Accuracy scores in 10 Folds\",\n",
    "            gbm_result[\"Training Accuracy scores\"],\n",
    "            gbm_result[\"Validation Accuracy scores\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
